{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6dbad637",
   "metadata": {},
   "source": [
    "# ICE 2: Handwritten Digits - DNN\n",
    "\n",
    "This notebook demonstrates the building and training of a deep neural network (DNN) for digit classification using the `load_digits` dataset from scikit-learn. The DNN is built using TensorFlow's Keras API.\n",
    "\n",
    "## Pre-Reading\n",
    "\n",
    "- Video [3Blue1Brown: But what is a neural network?](https://www.youtube.com/watch?v=aircAruvnKk)\n",
    "\n",
    "### Objectives\n",
    "\n",
    "- Understand the types of layers in a Neural Network and how they can be modified.\n",
    "- Describe TensorFlow and Keras at a conceptual level\n",
    "- Get a model for classifying handwritten digits\n",
    "\n",
    "This notebook is a modification of Chollet's, [*Deep Learning with Python*, 2.1 A first look at a neural network](https://learning.oreilly.com/library/view/deep-learning-with/9781617296864/Text/02.htm#:-:text=2.1%20A%20first%20look%20at%20a%20neural%20network) [GitHub notebook](https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/chapter02_mathematical-building-blocks.ipynb)\n",
    "with a few additions from [TensorFlow Tutorials](https://www.tensorflow.org/tutorials/images/transfer_learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933a086e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google colab includes by default, so you probably won't need to run\n",
    "%pip install -q matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f32422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Running Tensorflow version\", tf.__version__)\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name == \"/device:GPU:0\":\n",
    "    print(f\"Using GPU: {device_name}\")\n",
    "else:\n",
    "    print(\"No GPU detected; running on CPU.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40e65364",
   "metadata": {},
   "source": [
    "## The Dataset\n",
    "\n",
    "We will use the same handwritten digits dataset we used with K-Means.\n",
    "\n",
    "The MNIST dataset comes preloaded in Keras, in the form of a set of four **train** and **test** NumPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18566275",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc7a187",
   "metadata": {},
   "source": [
    "Visualize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6c0f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def show_images():\n",
    "    \"\"\"Show 100 random images from the dataset\"\"\"\n",
    "    array = np.random.randint(low=1, high=10000, size=100)\n",
    "    fig = plt.figure(figsize=(30, 35))\n",
    "    for i in range(100):\n",
    "        fig.add_subplot(10, 10, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(train_labels[array[i]], color=\"red\", fontsize=20)\n",
    "        plt.imshow(train_images[array[i]], cmap=\"gray\")\n",
    "\n",
    "\n",
    "show_images()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ba724a2d",
   "metadata": {},
   "source": [
    "### Set Splitting\n",
    "\n",
    "The dataset already comes split into two sets:\n",
    "\n",
    "- **train** is the set we will fit the model to\n",
    "- **test** is the set we will evaluate the model against\n",
    "\n",
    "In the upcoming Lab we will want to use this model to predict on digits *we* create!\n",
    "\n",
    "To do this we'll need to pass the network *exactly* the same shape tensor of the appropriate type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0584549e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: replace None with `type` function call on train_images\n",
    "# Upload the output of this cell to Gradescope\n",
    "print(\"Type model expects:\", type(train_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b1ba56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: replace None with `ndim` attribute of train_images\n",
    "# Upload the output of this cell to Gradescope\n",
    "print(\"Dimensions model expects:\", train_images.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2914fc51",
   "metadata": {},
   "source": [
    "It's also **extremely** helpful to know the shape of the training dataset.\n",
    "The first axis will be how many samples, the next axes will be how many features per axis... in this case, pixels!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "75e3cfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: print the shape of train_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04f85f0",
   "metadata": {},
   "source": [
    "What about the labels for the train set? How many and what's their type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02444bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d1c541",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f9cf99",
   "metadata": {},
   "source": [
    "How many samples are in the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c3c834",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33e7845",
   "metadata": {},
   "source": [
    "#### Validation Set\n",
    "\n",
    "To monitor overfitting, we will break out a *validation set* from out training set using scikit-learn [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
    "\n",
    "We will use `stratify` to make sure that the validation set contains a balanced representation of the labels present in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "daf719ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(\n",
    "    train_images, train_labels, test_size=0.15, random_state=37, stratify=train_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d986de13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"After split: train_images: {train_images.shape}, val_images: {val_images.shape}\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8bf8b9b8",
   "metadata": {},
   "source": [
    "## Build the Deep Neural Network\n",
    "\n",
    "We are going to build a deep(ish) neural network, remember that you aren’t expected to understand everything about this example yet.\n",
    "Layers get added into the model one at a time (sequential).\n",
    "\n",
    "The core building block of neural networks is the layer. You can think of a layer as a filter for data: some data goes in, and it comes out in a more useful form.\n",
    "\n",
    "We will assemble our model as a series of [Keras sequential layers](https://keras.io/guides/sequential_model/)\n",
    "\n",
    "> A `Sequential` model is appropriate for a plain stack of layers where each layer has **exactly one input tensor and one output tensor**.\n",
    "\n",
    "Here is the layer breakdown.\n",
    "The number and size of the hidden layers are arbitrarily chosen here... this is one of the greatest challenges in DNN.\n",
    "\n",
    "- [**Input**](https://keras.io/api/layers/core_layers/input/) tells our model what shape tensor to expect as an input.\n",
    "- [**Rescaling**](https://keras.io/api/layers/preprocessing_layers/image_preprocessing/rescaling/) preprocesses the pixel values from `[0, 255]` to `[0, 1]`, which helps prevent large values from skewing training.\n",
    "- [**Flatten**](https://keras.io/api/layers/reshaping_layers/flatten/) converts the 2D matrix input to a 1D vector, which is needed because the upcoming dense layer expects the shape `(batch_size, input_dim)`.\n",
    "- [**Dense**](https://keras.io/api/layers/core_layers/dense/) implements the operation: `output = activation(dot(input, kernel) + bias)`. We'll use [ReLU](https://keras.io/api/layers/activation_layers/relu/) (Rectified Linear Unit), which has the output `max(x, 0)`.\n",
    "- [**Dropout**](https://keras.io/api/layers/regularization_layers/dropout/) randomly sets some input units to 0. This tends to help prevent *overfitting*.\n",
    "- [**Softmax**](https://keras.io/api/layers/activation_layers/softmax/) converts a vector of K real numbers into a probability distribution of K possible outcomes.\n",
    "The sum of these probabilities equals 1. We will assign our sample to the class with the highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "315374eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Input(shape=(28, 28)),\n",
    "        layers.Rescaling(1.0 / 255),  # Normalize pixel values to [0, 1]\n",
    "        layers.Flatten(),  # Flatten input\n",
    "        layers.Dense(512, activation=\"relu\"),\n",
    "        layers.Dropout(0.2),  # Regularization to prevent overfitting\n",
    "        layers.Dense(256, activation=\"relu\"),\n",
    "        layers.Dropout(0.2),  # Another regularization layer\n",
    "        layers.Dense(10, activation=\"softmax\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a8d99f26",
   "metadata": {},
   "source": [
    "### Compile the Model\n",
    "\n",
    "To make the model ready for training, we need to pick three more things as part of the compilation step:\n",
    "\n",
    "- *Optimizer:* The mechanism through which the model will update itself based on the training data it sees, so as to improve its performance.\n",
    "- *Loss function*: How the model will be able to measure its performance on the training data, and thus how it will be able to steer itself in the right direction.\n",
    "- *Metrics*: to monitor during training and testing—Here, we’ll only care about accuracy (the fraction of the images that were correctly classified).\n",
    "\n",
    "Keras provides the [compile](https://keras.io/api/models/model_training_apis/) API which does A LOT of stuff under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a67281a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54774aa7",
   "metadata": {},
   "source": [
    "#### Visualize the Model\n",
    "\n",
    "We can print a summary of the model as well as a graphical represnetation.\n",
    "\n",
    "We should always do this [for a few reasons:](https://machinelearningmastery.com/visualize-deep-learning-neural-network-model-keras/)\n",
    "\n",
    "- **Confirm layer order**. It is easy to add layers in the wrong order with the sequential API or to connect them together incorrectly with the functional API. The graph plot can help you confirm that the model is connected the way you intended.\n",
    "- **Confirm the output shape of each layer**. It is common to have problems when defining the shape of input data for complex networks like convolutional and recurrent neural networks. The summary and plot can help you confirm the input shape to the network is as you intended.\n",
    "- **Confirm parameters**. Some network configurations can use far fewer parameters, such as the use of a TimeDistributed wrapped Dense layer in an Encoder-Decoder recurrent neural network. Reviewing the summary can help spot cases of using far more parameters than expected.\n",
    "\n",
    "Our \"Output Shape\" is unknown because we didn't specify an Input Layer. Instead, we need to transform our data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85beb063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should ALWAYS run this after compile\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087ac955",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "Keras offers a [fit](https://keras.io/api/models/model_training_apis/) API that will automatically train the model on our data for a set number of epochs.\n",
    "\n",
    "Two quantities are displayed during training: the loss of the model over the training data, and the accuracy of the model over the training data.\n",
    "\n",
    "Notice the accuracy increasing to over 98%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e709ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_data=(val_images, val_labels),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6a4c7b",
   "metadata": {},
   "source": [
    "### Loss History\n",
    "\n",
    "Let's plot the loss history.\n",
    "\n",
    "Based on validation loss vs. training loss, do you think overfitting is occurring?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945f33ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple plot of training and validation loss over the epochs\n",
    "\n",
    "plt.plot(history.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "# plt.ylim([0, 1])\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "adb0bda4",
   "metadata": {},
   "source": [
    "## Make a Prediction\n",
    "\n",
    "Finally, we can evaluate the accuracy of the trained model on the validation set.\n",
    "\n",
    "Now that we have a trained model, we can use it to predict class probabilities for new digits—images that weren’t part of the training data, like those from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a40a38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the first samples from the test dataset\n",
    "test_digits = test_images[0:5]\n",
    "\n",
    "# Make prediction on that sample\n",
    "prediction = model.predict(test_digits)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a1cd97",
   "metadata": {},
   "source": [
    "This is the output of the **softmax** layer.\n",
    "\n",
    "The sum of probabilities for these 10 elements is 1.\n",
    "\n",
    "Whichever class corresponds with the element that has highest probability is the class we predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c86afef",
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_prediction_index = prediction[0].argmax()\n",
    "print(\n",
    "    \"Index of highest probability:\",\n",
    "    highest_prediction_index,\n",
    "    \"with probability:\",\n",
    "    prediction[0][highest_prediction_index],\n",
    "    \"\\nTrue label:\",\n",
    "    test_labels[0],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3006dc98",
   "metadata": {},
   "source": [
    "Because index 7 has the highest probability (with over 99%), we predict that is the class.\n",
    "The true label agrees!\n",
    "\n",
    "And here is the image itself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4136f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first sample\n",
    "plt.imshow(test_digits[0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d461e7",
   "metadata": {},
   "source": [
    "### Overall Accuracy\n",
    "\n",
    "On average, how good is our model at classifying such never-before-seen digits? Let’s check by computing average accuracy over the entire test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c90200",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f\"test_acc: {test_acc}\")\n",
    "print(f\"test_loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb85f5c2",
   "metadata": {},
   "source": [
    "The test set will have a lower accuracy than the training set, partyl because of overfitting. We will address that later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe2b79f",
   "metadata": {},
   "source": [
    "## Save the Model\n",
    "\n",
    "We need to re-use this model later.\n",
    "Make sure to **download** the `digits.keras` file after you run this command!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "645406c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and keep this file after saving!\n",
    "model.save(\"digits.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5903ac8f",
   "metadata": {},
   "source": [
    "## Deliverables\n",
    "\n",
    "Submit the following to the Gradescope ICE 2 assignment:\n",
    "\n",
    "- The type and shape outputs\n",
    "- Your Keras model\n",
    "- This completed notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
