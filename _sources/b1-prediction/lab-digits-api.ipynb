{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Handwritten Digits - FastAPI\n",
    "\n",
    "In [ICE 2](./ice-digits-dnn.ipynb) we made a model. Now it's time to serve it so others can use it!\n",
    "\n",
    "**Objective:** one device (the *server*) expose an API that accepts POST HTTP requests containing an image; the method returns the inferred label of the digit in that image. A second device (the *client*) makes requests to the server's API using pre-produced images.\n",
    "\n",
    "## Collaboration Policy\n",
    "\n",
    "This Lab may be done in **teams of two**.\n",
    "\n",
    "Large Language Models (such as ChatGPT or Claude) are authorized for clarifying questions and how to do very specific things, *but* you cannot ask for a large chunk of the program. Furthermore, you **must document in your `README.md` by:**\n",
    "\n",
    "1. Stating  your  primary query AND\n",
    "2. Providing a link to the entire conversation.\n",
    "\n",
    "For example, this is ok:\n",
    "\n",
    "> \"In a FastAPI POST function how should I accept a PNG image?\"\n",
    "\n",
    "But this is **not** ok:\n",
    "\n",
    "> \"Write a FastAPI app with a POST method that feeds an image into a Keras model.\"\n",
    "\n",
    "```{warning}\n",
    "You really, really, need to be careful taking code from LLMs.\n",
    "\n",
    "A better approach might be \"I have this simple FastAPI method, but am new to using the package.\n",
    "Can you help explain and critique it for me?\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "You can complete this lab on your Raspberry Pi (recommended) or on a Linux VM of your choice.\n",
    "\n",
    "1. Make your own copy of the template repository: [https://github.com/USAFA-ECE/ece386-lab1](https://github.com/USAFA-ECE/ece386-lab1)\n",
    "2. Add and commit your Keras neural network model for predicting digits into `server/digits.keras`\n",
    "3. Make ten images of handwritten digits (one for each digit) place them into `client/img/`.\n",
    "    - You can use Paint or any application you want\n",
    "    - Pay attention to how many pixels these images should be\n",
    "    - Try to make them resemble images in the original dataset\n",
    "    - Save the image with the correct digit as the filename\n",
    "    - Use PNG format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab\n",
    "\n",
    "This lab will require significant self-learning! You'll absolutely need to spend time reading documentation.\n",
    "\n",
    "```{important}\n",
    "Remember to use type hints on function definitions and global variables!\n",
    "```\n",
    "\n",
    "### Server\n",
    "\n",
    "For the server you may either use a Raspberry Pi *or* the DFEC AI Server *or* any computer you want.\n",
    "\n",
    "All the code for the server will be located in the `server/` directory of your repository.\n",
    "\n",
    "1. Clone your repository and `cd` into `./server`\n",
    "2. Create and activate a virtual environment.\n",
    "3. Use `pip install -r requirements.txt` to install server packages.\n",
    "4. Serve the model with `fastapi run digits.py`\n",
    "\n",
    "The app should simply:\n",
    "\n",
    "- Open the previously saved Keras model.\n",
    "- Accept a POST request to `/predict`.\n",
    "- Reshape and grayscale the image to work with the model's input expectations.\n",
    "- Conduct inference on the image and return an integer of the predicted class.\n",
    "\n",
    "### Client\n",
    "\n",
    "For your client, you can use any machine with Python and on the same network as the Pi. This can include another Raspberry Pi or your laptop.\n",
    "All the code for the client will be in the `client/` directory of your repository.\n",
    "\n",
    "1. Clone your repository and `cd` into `./client/`\n",
    "2. Create and activate a virtual environment.\n",
    "3. Use `pip install -r requirements.txt` to install client packages.\n",
    "4. Run `client.py xxx.xxx.xxx.xxx 8000`, where the X's are the IP address of the server and the number is the port.\n",
    "5. `client.py` prompts the user for a path to an image. After hitting \"enter\" the client makes an HTTP POST request to the server, waits for the response, then displays the integer to the user.\n",
    "6. The client continues to prompt the user until the user exits with CTRL+C.\n",
    "\n",
    "```{tip}\n",
    "The [requests](https://requests.readthedocs.io/en/latest/) package is easier to use than the built-in urllib.\n",
    "```\n",
    "\n",
    "### Deliverables\n",
    "\n",
    "```{note}\n",
    "The lab1 repo has a GitHub Action that Lints with Black and Pyright on both the client and the server.\n",
    "\n",
    "You should ensure the Action is passing prior to submitting to Gradescope.\n",
    "```\n",
    "\n",
    "- Use a web browser to visit `<yourserver_ip>:<your_server_port>/redoc`. ☺️ at how beautfiul your API documentation is.\n",
    "- Demonstrate your client-server exchange.\n",
    "- Complete the three README's in the repository (root, client, server).\n",
    "- Push your code and submit to Gradescope (see GitHub Actions below)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
